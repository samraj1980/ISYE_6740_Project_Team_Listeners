{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import json\n",
    "from requests.exceptions import Timeout, ConnectionError\n",
    "import time\n",
    "from time import sleep\n",
    "import configparser\n",
    "import ssl\n",
    "import pandas as pd\n",
    "import pyodbc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "from scipy.stats import stats\n",
    "import spacy\n",
    "from tqdm import *\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Setting the connection strings\n",
    "server = 'tcp:isye-6420-project.database.windows.net,1433' \n",
    "database = 'topic_modelling' \n",
    "username = 'project_administrator' \n",
    "password = 'isye_6420_admin' \n",
    "conn = pyodbc.connect('DRIVER={ODBC Driver 17 for SQL Server};SERVER='+server+';DATABASE='+database+';UID='+username+';PWD='+ password)\n",
    "#SQLite cursor\n",
    "c = conn.cursor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Method to read the twitter messages into the pandas dataframe\n",
    "def read_sql():\n",
    "    train_data =  pd.read_sql_query('SELECT  [tweet_text],[final_normalized_topic] FROM topic_modelling_ensemble_V4', conn) \n",
    "    return(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data=read_sql()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              tweet_text  \\\n",
      "0      In 2016, there wasn't a single question on cli...   \n",
      "1      A leader among the next generation of Democrat...   \n",
      "2      A moving tribute from Mayor @KeishaBottoms for...   \n",
      "3      Let's never forget that the Trump administrati...   \n",
      "4      Incredibly powerful words from @GabbyGiffords ...   \n",
      "...                                                  ...   \n",
      "53696  “7 in 10 Americans say the economy is in good ...   \n",
      "53697  #MedicareForAll costs $32 trillion, imposes a ...   \n",
      "53698  SC is enjoying lower gas prices than during th...   \n",
      "53699  -Over 7 in 10 Americans feel positively about ...   \n",
      "53700  Met with SSG Amanda Kelley, an Easley native, ...   \n",
      "\n",
      "         final_normalized_topic  \n",
      "0      job economy unemployment  \n",
      "1               veteran service  \n",
      "2            vote election mail  \n",
      "3               veteran service  \n",
      "4                  gun violence  \n",
      "...                         ...  \n",
      "53696  job economy unemployment  \n",
      "53697               health care  \n",
      "53698         drug prescription  \n",
      "53699  job economy unemployment  \n",
      "53700           veteran service  \n",
      "\n",
      "[53701 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to read the new harnessed twitter messages into the pandas dataframe\n",
    "def read_sql1():\n",
    "    test_data_1 =  pd.read_sql_query('select [tweet_text],[political_party],[time],[user] from tweets_test', conn) \n",
    "    return(test_data_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 : Data Loading \n",
    "    \n",
    "# Executing method to read twitter messages into dataframe\n",
    "test_data_1 = read_sql1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             tweet_text   political_party  \\\n",
      "0     Our men and women in uniform make great sacrif...  Democratic Party   \n",
      "1                          COUNT EVERY MILITARY BALLOT!  Republican Party   \n",
      "2     #ICYMI An important move for ensuring the rule...  Republican Party   \n",
      "3     I know 75 million Americans willing to help yo...  Democratic Party   \n",
      "4                               https://t.co/ZhdVxJKv77  Democratic Party   \n",
      "...                                                 ...               ...   \n",
      "7663  Don’t let the line scare you...it moves quick!...  Democratic Party   \n",
      "7664  We need 60% of the population to have #COVID19...  Democratic Party   \n",
      "7665  You can vote early this week! Check out the lo...  Democratic Party   \n",
      "7666  7 more days left to vote!\\n\\nhttps://t.co/g89Z...  Democratic Party   \n",
      "7667  My statement on the U.S. Senate’s confirmation...  Republican Party   \n",
      "\n",
      "                     time             user  \n",
      "0     2020-11-05 21:00:00       RepTedLieu  \n",
      "1     2020-11-05 22:07:05     RepMattGaetz  \n",
      "2     2020-11-07 13:23:40   WarrenDavidson  \n",
      "3     2020-11-07 17:34:55    RepJoeKennedy  \n",
      "4     2020-11-07 16:47:40     BillPascrell  \n",
      "...                   ...              ...  \n",
      "7663  2020-10-28 13:47:26        RepBeatty  \n",
      "7664  2020-10-28 16:10:15  CongressmanRaja  \n",
      "7665  2020-10-27 18:02:16  CongressmanRaja  \n",
      "7666  2020-10-27 13:02:59  CongressmanRaja  \n",
      "7667  2020-10-27 00:36:20  RepDavidKustoff  \n",
      "\n",
      "[7668 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(test_data_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             tweet_text\n",
      "0     Our men and women in uniform make great sacrif...\n",
      "1                          COUNT EVERY MILITARY BALLOT!\n",
      "2     #ICYMI An important move for ensuring the rule...\n",
      "3     I know 75 million Americans willing to help yo...\n",
      "4                               https://t.co/ZhdVxJKv77\n",
      "...                                                 ...\n",
      "7663  Don’t let the line scare you...it moves quick!...\n",
      "7664  We need 60% of the population to have #COVID19...\n",
      "7665  You can vote early this week! Check out the lo...\n",
      "7666  7 more days left to vote!\\n\\nhttps://t.co/g89Z...\n",
      "7667  My statement on the U.S. Senate’s confirmation...\n",
      "\n",
      "[7668 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Method to read the new harnessed twitter messages into the pandas dataframe\n",
    "def read_sql11():\n",
    "    test_data =  pd.read_sql_query('select [tweet_text] from tweets_test', conn) \n",
    "    return(test_data)\n",
    "# Step 1 : Data Loading \n",
    "    \n",
    "# Executing method to read twitter messages into dataframe\n",
    "test_data = read_sql11()\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['tweet_text'], dtype='object')\n",
      "0        in 2016 there wasn't a single question on clim...\n",
      "1        a leader among the next generation of democrat...\n",
      "2        a moving tribute from mayor keishabottoms for ...\n",
      "3        let's never forget that the trump administrati...\n",
      "4        incredibly powerful words from gabbygiffords -...\n",
      "                               ...                        \n",
      "53696    “7 in 10 americans say the economy is in good ...\n",
      "53697    #medicareforall costs $32 trillion imposes a g...\n",
      "53698    sc is enjoying lower gas prices than during th...\n",
      "53699    -over 7 in 10 americans feel positively about ...\n",
      "53700    met with ssg amanda kelley an easley native in...\n",
      "Name: tweet_text, Length: 53701, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Data Cleaning \n",
    "\n",
    "   \n",
    "# print the train_data column names \n",
    "print(test_data.columns)\n",
    "\n",
    "# Load the regular expression library\n",
    "import re\n",
    "\n",
    "#  Remove URLs\n",
    "train_data['tweet_text'] = train_data['tweet_text'].apply(lambda x: re.split('https:\\/\\/.*', str(x))[0])\n",
    "\n",
    "# Remove punctuation\n",
    "train_data['tweet_text'] = train_data['tweet_text'].map(lambda x: re.sub('[,\\.!?@]', '', x))\n",
    "\n",
    "# Convert the titles to lowercase\n",
    "train_data['tweet_text'] = train_data['tweet_text'].map(lambda x: x.lower())\n",
    "\n",
    "# Removing the word 'amp' \n",
    "train_data['tweet_text'] = train_data['tweet_text'].map(lambda x: re.sub('amp', '', x))\n",
    "\n",
    "# Removing Stopwords \n",
    "#import nltk \n",
    "#nltk.download('stopwords')  #First time after you have installed nltk\n",
    "#from nltk.corpus import stopwords\n",
    "#STOPWORDS = stopwords.words('english')\n",
    "#train_data['tweet_text'] = train_data['tweet_text'].apply(lambda x: [item for item in x if item not in STOPWORDS])\n",
    "\n",
    "print(train_data['tweet_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      2016 single question climate change presidenti...\n",
      "1      leader among next generation democrats - commi...\n",
      "2      moving tribute mayor keishabottoms dear friend...\n",
      "3      let's never forget trump administration extrem...\n",
      "4      incredibly powerful words gabbygiffords - turn...\n",
      "                             ...                        \n",
      "995    thank youth conservation corps (npsyouth) team...\n",
      "996    trump admin’s decision end #2020census month e...\n",
      "997    see stronger economy bringing people disabilit...\n",
      "998    thank rep jimlangevin partnering bipartisan le...\n",
      "999    congratulations abackyardfarm’s joan james col...\n",
      "Name: tweet_text, Length: 1000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "       \n",
    "# 5. Removing Stopwords \n",
    "\n",
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "STOPWORDS = set(stopwords.words('english','spanish'))\n",
    "def remove(text,wordset=STOPWORDS):\n",
    "    splits = text.split()\n",
    "    result=[]\n",
    "    for split in splits:\n",
    "        if split not in wordset:\n",
    "            result.append(split)\n",
    "    return (\" \".join(result))  \n",
    "train_data['tweet_text'] = train_data['tweet_text'].apply(lambda x: remove(x))\n",
    "\n",
    "print(train_data['tweet_text'].head(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  6. To retain only the Nouns and Adjectives in every tweet \n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    doc = nlp(texts) \n",
    "    texts_out = \" \".join([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out     \n",
    "\n",
    "# Do lemmatization keeping only noun, adj parts of speech (POS)\n",
    "train_data['tweet_text'] = train_data['tweet_text'].apply(lambda x: lemmatization(x, allowed_postags=['NOUN', 'ADJ']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              tweet_text  \\\n",
      "0      single climate change presidential debate lett...   \n",
      "1      next generation service future first step well...   \n",
      "2                    mayor dear vote text vote plan vote   \n",
      "3      administration extreme immigration spouse mili...   \n",
      "4      powerful gabbygifford tragedy purpose end gun ...   \n",
      "...                                                  ...   \n",
      "53696                        economy shape quarter potus   \n",
      "53697  medicareforall size health plan taxis choice l...   \n",
      "53698  low gas price obama republican above energy pr...   \n",
      "53699                    job market optimism workforce %   \n",
      "53700                                          service #   \n",
      "\n",
      "         final_normalized_topic  \n",
      "0      job economy unemployment  \n",
      "1               veteran service  \n",
      "2            vote election mail  \n",
      "3               veteran service  \n",
      "4                  gun violence  \n",
      "...                         ...  \n",
      "53696  job economy unemployment  \n",
      "53697               health care  \n",
      "53698         drug prescription  \n",
      "53699  job economy unemployment  \n",
      "53700           veteran service  \n",
      "\n",
      "[53701 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# 7. To eliminate additional words \n",
    "\n",
    "\n",
    "eliminate_words = ['today', 'year', 'people', 'time', 'great', 'day', 'morning', 'evening', 'community', 'important',\n",
    "                   'many', 'family', 'sure', 'visit', 'https', 'new', 'work', 'proud', 'thank', 'good', 'way', 'help',\n",
    "                   'need', 'member', 'week', 'nation', 'support', 'last', 'effort', 'yesterday', 'news', 'watch', 'state',\n",
    "                   'safe', 'happy', 'birthday', 'colleague', 'tonight', 'part', 'much', 'now', 'country', 'leader', 'program',\n",
    "                   'congratulation', 'conversation', 'fact', 'government', 'house', 'right', 'tomorrow', 'question', 'long',\n",
    "                   'public', 'big', 'million', 'benefit', 'information', 'report' , 'friend', 'life', 'bad' , 'word', 'true',\n",
    "                   'woman', 'man', 'local', 'action', 'resource', 'high','school', 'opportunity', 'town', 'event', 'meeting',\n",
    "                   'tune', 'pm', 'student', 'live', 'discussion', 'discuss', 'child', 'world', 'policy', 'condition', 'hand',  \n",
    "                   'office', 'place', 'resident', 'site' , 'concern', 'city', 'free', 'congressional', 'WORKER', 'history',\n",
    "                   'M', 'P', 'wonderful', 'team', 'update', 'facebook', 'minute', 'op', 'water', 'food', 'hour', 'pm', \n",
    "                   'thing', 'art', 'folk', 'annual', 'prayer', 'thought', 'heart', 'statement', 'story', 'special', 'pre',\n",
    "                   'honor', 'young', 'neighbor', 'night', 'district', 'late', 'moment', 'case', 'census', 'person', 'voice', \n",
    "                   'wrong',  'share', 'victory', 'grateful', 'century', 'kid', 'difficult', 'afternoon', 'love', 'youth', \n",
    "                   'fellow', 'mother',  'comment', 'official','p','m', 'crisis', 'issue']\n",
    "\n",
    "train_data['tweet_text'] = train_data['tweet_text'].apply(lambda x: remove(x, wordset=eliminate_words ))\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              tweet_text  \\\n",
      "0      single climate change presidential debate lett...   \n",
      "1      next generation service future first step well...   \n",
      "2                    mayor dear vote text vote plan vote   \n",
      "3      administration extreme immigration spouse mili...   \n",
      "4      powerful gabbygifford tragedy purpose end gun ...   \n",
      "...                                                  ...   \n",
      "53696                        economy shape quarter potus   \n",
      "53697  medicareforall size health plan taxis choice l...   \n",
      "53698  low gas price obama republican above energy pr...   \n",
      "53699                    job market optimism workforce %   \n",
      "53700                                          service #   \n",
      "\n",
      "         final_normalized_topic  \n",
      "0      job economy unemployment  \n",
      "1               veteran service  \n",
      "2            vote election mail  \n",
      "3               veteran service  \n",
      "4                  gun violence  \n",
      "...                         ...  \n",
      "53696  job economy unemployment  \n",
      "53697               health care  \n",
      "53698         drug prescription  \n",
      "53699  job economy unemployment  \n",
      "53700           veteran service  \n",
      "\n",
      "[53701 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "def replace_synonyms(text):\n",
    "    splits = text.split()\n",
    "    result=[]\n",
    "    for split in splits:\n",
    "        if split in synonyms:\n",
    "            result.append(synonyms[split])\n",
    "        else:\n",
    "            result.append(split)\n",
    "    return (\" \".join(result))        \n",
    "\n",
    "#replace synonyms\n",
    "synonyms = {'donald':'trump','realdonaldtrump':'trump','joebiden':'biden'}\n",
    "synonyms = {'paycheck protection':'paycheck protection program','protection program':'paycheck protection program'}\n",
    "synonyms = {'admin':'administration'}\n",
    "synonyms = {'realdonaldtrump':'trump'}\n",
    "train_data['tweet_text'] = train_data['tweet_text'].apply(lambda x: replace_synonyms(x))\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        single climate change presidential debate lett...\n",
      "1        next generation service future first step well...\n",
      "2                      mayor dear vote text vote plan vote\n",
      "3        administration extreme immigration spouse mili...\n",
      "4        powerful gabbygifford tragedy purpose end gun ...\n",
      "                               ...                        \n",
      "53696                          economy shape quarter potus\n",
      "53697    medicareforall size health plan taxis choice l...\n",
      "53698    low gas price obama republican above energy pr...\n",
      "53699                      job market optimism workforce %\n",
      "53700                                            service #\n",
      "Name: tweet_text, Length: 53701, dtype: object\n"
     ]
    }
   ],
   "source": [
    "x_training=train_data['tweet_text']\n",
    "print(x_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#from self import self\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(x_training)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "# after trainning the data\n",
    "#vector = CountVectorizer()\n",
    "#vector.fit(self.x_training)\n",
    "#X_train = vector.transform(self.x_training)\n",
    "\n",
    "\n",
    "# use vector.vocabulary for predict\n",
    "#vector = CountVectorizer(vocabulary=vector.vocabulary_) #vocabulary is a parameter, it should be vocabulary_ as it is an attribute.\n",
    "#text_vector = vector.transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 15287)\t0.2105767306024062\n",
      "  (0, 12813)\t0.23477427584072535\n",
      "  (0, 10537)\t0.33802822791627035\n",
      "  (0, 9419)\t0.18072655874507373\n",
      "  (0, 6464)\t0.2344508749888831\n",
      "  (0, 4250)\t0.6959232415236806\n",
      "  (0, 3054)\t0.3318602165094053\n",
      "  (0, 2704)\t0.32280912913154225\n",
      "  (1, 18407)\t0.24514690495452202\n",
      "  (1, 15864)\t0.24077157939710758\n",
      "  (1, 15016)\t0.18135759019158348\n",
      "  (1, 11177)\t0.24123776487061196\n",
      "  (1, 8935)\t0.4159307167945514\n",
      "  (1, 6904)\t0.24817601075890938\n",
      "  (1, 6787)\t0.4331113275844159\n",
      "  (1, 6312)\t0.227681098576863\n",
      "  (1, 4434)\t0.31468256729049354\n",
      "  (1, 4421)\t0.4666978577719204\n",
      "  (2, 18169)\t0.6598297025127012\n",
      "  (2, 16624)\t0.4107965121454525\n",
      "  (2, 12456)\t0.2702186570340643\n",
      "  (2, 10064)\t0.4151807607333811\n",
      "  (2, 4242)\t0.38791468469070484\n",
      "  (3, 18024)\t0.2552379080459617\n",
      "  (3, 15684)\t0.44989025353661205\n",
      "  :\t:\n",
      "  (53697, 9885)\t0.32990852145478033\n",
      "  (53697, 9411)\t0.26919016631226445\n",
      "  (53697, 9327)\t0.2758348024006175\n",
      "  (53697, 7602)\t0.14386417487524417\n",
      "  (53697, 5568)\t0.2601351958182377\n",
      "  (53697, 4416)\t0.26982922088872896\n",
      "  (53697, 2852)\t0.2765886159088185\n",
      "  (53697, 2448)\t0.15723955681283502\n",
      "  (53697, 401)\t0.19151516582410608\n",
      "  (53697, 360)\t0.2525960905282146\n",
      "  (53698, 13999)\t0.26596655105876194\n",
      "  (53698, 12920)\t0.3270333445817971\n",
      "  (53698, 12849)\t0.2508592107659211\n",
      "  (53698, 11476)\t0.3794638707296146\n",
      "  (53698, 9687)\t0.22588876324916202\n",
      "  (53698, 7843)\t0.23291180616057983\n",
      "  (53698, 7133)\t0.3934126449589707\n",
      "  (53698, 6859)\t0.3036088619079109\n",
      "  (53698, 5532)\t0.2550420640326025\n",
      "  (53698, 363)\t0.44510208374539006\n",
      "  (53699, 18698)\t0.5198115915062588\n",
      "  (53699, 11711)\t0.6582671060094658\n",
      "  (53699, 9962)\t0.45152175549414114\n",
      "  (53699, 8922)\t0.3043163334379907\n",
      "  (53700, 15016)\t1.0\n"
     ]
    }
   ],
   "source": [
    "print(X_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        job economy unemployment\n",
      "1                 veteran service\n",
      "2              vote election mail\n",
      "3                 veteran service\n",
      "4                    gun violence\n",
      "                   ...           \n",
      "53696    job economy unemployment\n",
      "53697                 health care\n",
      "53698           drug prescription\n",
      "53699    job economy unemployment\n",
      "53700             veteran service\n",
      "Name: final_normalized_topic, Length: 53701, dtype: object\n"
     ]
    }
   ],
   "source": [
    "Y_train=train_data['final_normalized_topic']\n",
    "print(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB()\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "clf = MultinomialNB().fit(X_train_tfidf, Y_train)\n",
    "print(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['tweet_text'], dtype='object')\n",
      "0       our men and women in uniform make great sacrif...\n",
      "1                             count every military ballot\n",
      "2       #icymi an important move for ensuring the rule...\n",
      "3       i know 75 million americans willing to help yo...\n",
      "4                                                        \n",
      "                              ...                        \n",
      "7663    don’t let the line scare youit moves quick \\n\\...\n",
      "7664    we need 60% of the population to have #covid19...\n",
      "7665    you can vote early this week check out the loc...\n",
      "7666                         7 more days left to vote\\n\\n\n",
      "7667    my statement on the us senate’s confirmation o...\n",
      "Name: tweet_text, Length: 7668, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Data Cleaning \n",
    "\n",
    "   \n",
    "# print the test_data column names \n",
    "print(test_data.columns)\n",
    "\n",
    "# Load the regular expression library\n",
    "import re\n",
    "\n",
    "#  Remove URLs\n",
    "test_data['tweet_text'] = test_data['tweet_text'].apply(lambda x: re.split('https:\\/\\/.*', str(x))[0])\n",
    "\n",
    "# Remove punctuation\n",
    "test_data['tweet_text'] = test_data['tweet_text'].map(lambda x: re.sub('[,\\.!?@]', '', x))\n",
    "\n",
    "# Convert the titles to lowercase\n",
    "test_data['tweet_text'] = test_data['tweet_text'].map(lambda x: x.lower())\n",
    "\n",
    "# Removing the word 'amp' \n",
    "test_data['tweet_text'] = test_data['tweet_text'].map(lambda x: re.sub('amp', '', x))\n",
    "\n",
    "# Removing Stopwords \n",
    "#import nltk \n",
    "#nltk.download('stopwords')  #First time after you have installed nltk\n",
    "#from nltk.corpus import stopwords\n",
    "#STOPWORDS = stopwords.words('english')\n",
    "#train_data['tweet_text'] = train_data['tweet_text'].apply(lambda x: [item for item in x if item not in STOPWORDS])\n",
    "\n",
    "print(test_data['tweet_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       men women uniform make great sacrifices protec...\n",
      "1                             count every military ballot\n",
      "2       #icymi important move ensuring rules honestly ...\n",
      "3             know 75 million americans willing help pack\n",
      "4                                                        \n",
      "                              ...                        \n",
      "7663    don’t let line scare youit moves quick can’t w...\n",
      "7664    need 60% population #covid19 antibodies reach ...\n",
      "7665    vote early week check locations times various ...\n",
      "7666                                     7 days left vote\n",
      "7667    statement us senate’s confirmation judge amy c...\n",
      "Name: tweet_text, Length: 7668, dtype: object\n"
     ]
    }
   ],
   "source": [
    "       \n",
    "# 5. Removing Stopwords \n",
    "\n",
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "STOPWORDS = set(stopwords.words('english','spanish'))\n",
    "def remove(text,wordset=STOPWORDS):\n",
    "    splits = text.split()\n",
    "    result=[]\n",
    "    for split in splits:\n",
    "        if split not in wordset:\n",
    "            result.append(split)\n",
    "    return (\" \".join(result))  \n",
    "test_data['tweet_text'] = test_data['tweet_text'].apply(lambda x: remove(x))\n",
    "\n",
    "print(test_data['tweet_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  6. To retain only the Nouns and Adjectives in every tweet \n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    doc = nlp(texts) \n",
    "    texts_out = \" \".join([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out     \n",
    "\n",
    "# Do lemmatization keeping only noun, adj parts of speech (POS)\n",
    "test_data['tweet_text'] = test_data['tweet_text'].apply(lambda x: lemmatization(x, allowed_postags=['NOUN', 'ADJ']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             tweet_text\n",
      "0                     sacrifice virtual veteran p.m. pt\n",
      "1                                       military ballot\n",
      "2                                             move rule\n",
      "3                                               willing\n",
      "4                                                      \n",
      "...                                                 ...\n",
      "7663       line scare youit move quick # yourvotematter\n",
      "7664  % population # covid19 antibody herd immunity ...\n",
      "7665  early check location various early voting polling\n",
      "7666                                               vote\n",
      "7667             confirmation judge scotus acbconfirmed\n",
      "\n",
      "[7668 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# 7. To eliminate additional words \n",
    "\n",
    "\n",
    "eliminate_words = ['today', 'year', 'people', 'time', 'great', 'day', 'morning', 'evening', 'community', 'important',\n",
    "                   'many', 'family', 'sure', 'visit', 'https', 'new', 'work', 'proud', 'thank', 'good', 'way', 'help',\n",
    "                   'need', 'member', 'week', 'nation', 'support', 'last', 'effort', 'yesterday', 'news', 'watch', 'state',\n",
    "                   'safe', 'happy', 'birthday', 'colleague', 'tonight', 'part', 'much', 'now', 'country', 'leader', 'program',\n",
    "                   'congratulation', 'conversation', 'fact', 'government', 'house', 'right', 'tomorrow', 'question', 'long',\n",
    "                   'public', 'big', 'million', 'benefit', 'information', 'report' , 'friend', 'life', 'bad' , 'word', 'true',\n",
    "                   'woman', 'man', 'local', 'action', 'resource', 'high','school', 'opportunity', 'town', 'event', 'meeting',\n",
    "                   'tune', 'pm', 'student', 'live', 'discussion', 'discuss', 'child', 'world', 'policy', 'condition', 'hand',  \n",
    "                   'office', 'place', 'resident', 'site' , 'concern', 'city', 'free', 'congressional', 'WORKER', 'history',\n",
    "                   'M', 'P', 'wonderful', 'team', 'update', 'facebook', 'minute', 'op', 'water', 'food', 'hour', 'pm', \n",
    "                   'thing', 'art', 'folk', 'annual', 'prayer', 'thought', 'heart', 'statement', 'story', 'special', 'pre',\n",
    "                   'honor', 'young', 'neighbor', 'night', 'district', 'late', 'moment', 'case', 'census', 'person', 'voice', \n",
    "                   'wrong',  'share', 'victory', 'grateful', 'century', 'kid', 'difficult', 'afternoon', 'love', 'youth', \n",
    "                   'fellow', 'mother',  'comment', 'official','p','m', 'crisis', 'issue']\n",
    "\n",
    "test_data['tweet_text'] = test_data['tweet_text'].apply(lambda x: remove(x, wordset=eliminate_words ))\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             tweet_text\n",
      "0                     sacrifice virtual veteran p.m. pt\n",
      "1                                       military ballot\n",
      "2                                             move rule\n",
      "3                                               willing\n",
      "4                                                      \n",
      "...                                                 ...\n",
      "7663       line scare youit move quick # yourvotematter\n",
      "7664  % population # covid19 antibody herd immunity ...\n",
      "7665  early check location various early voting polling\n",
      "7666                                               vote\n",
      "7667             confirmation judge scotus acbconfirmed\n",
      "\n",
      "[7668 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "def replace_synonyms(text):\n",
    "    splits = text.split()\n",
    "    result=[]\n",
    "    for split in splits:\n",
    "        if split in synonyms:\n",
    "            result.append(synonyms[split])\n",
    "        else:\n",
    "            result.append(split)\n",
    "    return (\" \".join(result))        \n",
    "\n",
    "#replace synonyms\n",
    "synonyms = {'donald':'trump','realdonaldtrump':'trump','joebiden':'biden'}\n",
    "synonyms = {'paycheck protection':'paycheck protection program','protection program':'paycheck protection program'}\n",
    "synonyms = {'admin':'administration'}\n",
    "synonyms = {'realdonaldtrump':'trump'}\n",
    "test_data['tweet_text'] = test_data['tweet_text'].apply(lambda x: replace_synonyms(x))\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=test_data['tweet_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#count_vect = CountVectorizer()\n",
    "X_test= count_vect.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['veteran service' 'vote election mail' 'health care' ...\n",
      " 'vote election mail' 'vote election mail' 'health care']\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7668\n"
     ]
    }
   ],
   "source": [
    "print(len(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>political_party</th>\n",
       "      <th>time</th>\n",
       "      <th>User</th>\n",
       "      <th>Predicted_topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our men and women in uniform make great sacrif...</td>\n",
       "      <td>Democratic Party</td>\n",
       "      <td>2020-11-05 21:00:00</td>\n",
       "      <td>RepTedLieu</td>\n",
       "      <td>veteran service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COUNT EVERY MILITARY BALLOT!</td>\n",
       "      <td>Republican Party</td>\n",
       "      <td>2020-11-05 22:07:05</td>\n",
       "      <td>RepMattGaetz</td>\n",
       "      <td>vote election mail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#ICYMI An important move for ensuring the rule...</td>\n",
       "      <td>Republican Party</td>\n",
       "      <td>2020-11-07 13:23:40</td>\n",
       "      <td>WarrenDavidson</td>\n",
       "      <td>health care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I know 75 million Americans willing to help yo...</td>\n",
       "      <td>Democratic Party</td>\n",
       "      <td>2020-11-07 17:34:55</td>\n",
       "      <td>RepJoeKennedy</td>\n",
       "      <td>veteran service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://t.co/ZhdVxJKv77</td>\n",
       "      <td>Democratic Party</td>\n",
       "      <td>2020-11-07 16:47:40</td>\n",
       "      <td>BillPascrell</td>\n",
       "      <td>job economy unemployment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7663</th>\n",
       "      <td>Don’t let the line scare you...it moves quick!...</td>\n",
       "      <td>Democratic Party</td>\n",
       "      <td>2020-10-28 13:47:26</td>\n",
       "      <td>RepBeatty</td>\n",
       "      <td>vote election mail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7664</th>\n",
       "      <td>We need 60% of the population to have #COVID19...</td>\n",
       "      <td>Democratic Party</td>\n",
       "      <td>2020-10-28 16:10:15</td>\n",
       "      <td>CongressmanRaja</td>\n",
       "      <td>covid19 testing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7665</th>\n",
       "      <td>You can vote early this week! Check out the lo...</td>\n",
       "      <td>Democratic Party</td>\n",
       "      <td>2020-10-27 18:02:16</td>\n",
       "      <td>CongressmanRaja</td>\n",
       "      <td>vote election mail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7666</th>\n",
       "      <td>7 more days left to vote!\\n\\nhttps://t.co/g89Z...</td>\n",
       "      <td>Democratic Party</td>\n",
       "      <td>2020-10-27 13:02:59</td>\n",
       "      <td>CongressmanRaja</td>\n",
       "      <td>vote election mail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7667</th>\n",
       "      <td>My statement on the U.S. Senate’s confirmation...</td>\n",
       "      <td>Republican Party</td>\n",
       "      <td>2020-10-27 00:36:20</td>\n",
       "      <td>RepDavidKustoff</td>\n",
       "      <td>health care</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7668 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweet   political_party  \\\n",
       "0     Our men and women in uniform make great sacrif...  Democratic Party   \n",
       "1                          COUNT EVERY MILITARY BALLOT!  Republican Party   \n",
       "2     #ICYMI An important move for ensuring the rule...  Republican Party   \n",
       "3     I know 75 million Americans willing to help yo...  Democratic Party   \n",
       "4                               https://t.co/ZhdVxJKv77  Democratic Party   \n",
       "...                                                 ...               ...   \n",
       "7663  Don’t let the line scare you...it moves quick!...  Democratic Party   \n",
       "7664  We need 60% of the population to have #COVID19...  Democratic Party   \n",
       "7665  You can vote early this week! Check out the lo...  Democratic Party   \n",
       "7666  7 more days left to vote!\\n\\nhttps://t.co/g89Z...  Democratic Party   \n",
       "7667  My statement on the U.S. Senate’s confirmation...  Republican Party   \n",
       "\n",
       "                     time             User           Predicted_topic  \n",
       "0     2020-11-05 21:00:00       RepTedLieu           veteran service  \n",
       "1     2020-11-05 22:07:05     RepMattGaetz        vote election mail  \n",
       "2     2020-11-07 13:23:40   WarrenDavidson               health care  \n",
       "3     2020-11-07 17:34:55    RepJoeKennedy           veteran service  \n",
       "4     2020-11-07 16:47:40     BillPascrell  job economy unemployment  \n",
       "...                   ...              ...                       ...  \n",
       "7663  2020-10-28 13:47:26        RepBeatty        vote election mail  \n",
       "7664  2020-10-28 16:10:15  CongressmanRaja           covid19 testing  \n",
       "7665  2020-10-27 18:02:16  CongressmanRaja        vote election mail  \n",
       "7666  2020-10-27 13:02:59  CongressmanRaja        vote election mail  \n",
       "7667  2020-10-27 00:36:20  RepDavidKustoff               health care  \n",
       "\n",
       "[7668 rows x 5 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pd.options.display.float_format = '{:,.16f}'.format\n",
    "df={\"tweet\":test_data_1[\"tweet_text\"],\"political_party\":test_data_1[\"political_party\"],'time':test_data_1[\"time\"],'User':test_data_1['user'],\"Predicted_topic\":y_pred}\n",
    "d = pd.DataFrame(data=df)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = d.rename(columns={\"tweet\": \"tweet_text\", \"time\": \"tweet_time\", \"User\": \"tweet_user\"})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "## Setting the connection strings\n",
    "server = 'tcp:isye-6420-project.database.windows.net,1433' \n",
    "database = 'topic_modelling' \n",
    "username = 'project_administrator' \n",
    "password = 'isye_6420_admin' \n",
    "conn = pyodbc.connect('DRIVER={ODBC Driver 17 for SQL Server};SERVER='+server+';DATABASE='+database+';UID='+username+';PWD='+ password)\n",
    "##SQLite cursor\n",
    "c = conn.cursor()\n",
    "## Creating the topic_modelling_ensemble Table \n",
    "temp_creator = '''CREATE TABLE topic_prediction (tweet_text nvarchar(max), political_party nvarchar(50) , tweet_time nvarchar(50), tweet_user nvarchar(50), Predicted_topic nvarchar(50));'''\n",
    "c.execute(temp_creator)\n",
    "c.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 16.367491483688354 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from urllib.parse import quote_plus\n",
    "import pyodbc\n",
    "from sqlalchemy import create_engine, MetaData, Table, select\n",
    "server = 'tcp:isye-6420-project.database.windows.net,1433' \n",
    "database = 'topic_modelling' \n",
    "username = 'project_administrator' \n",
    "password = 'isye_6420_admin' \n",
    "conn ='DRIVER={ODBC Driver 17 for SQL Server};SERVER='+server+';DATABASE='+database+';UID='+username+';PWD='+ password +';Encrypt=yes;TrustServerCertificate=no;Connection Timeout=30;'\n",
    "quoted = quote_plus(conn)\n",
    "engine=create_engine('mssql+pyodbc:///?odbc_connect={}'.format(quoted))\n",
    "conn = engine.connect()\n",
    "TableName = 'topic_prediction'\n",
    "metadata = MetaData(conn)\n",
    "start_time = time.time()\n",
    "\n",
    "d.to_sql(TableName,conn, method='multi', index=False, if_exists='append', chunksize=100)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
